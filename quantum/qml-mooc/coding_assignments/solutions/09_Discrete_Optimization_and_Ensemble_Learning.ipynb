{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, execute this cell to import numpy and packages from the D-Wave Ocean suite, and all necessary functions for the gate-model framework you are going to use, whether that is the Forest SDK or Qiskit. In the case of Forest SDK, it also starts the qvm and quilc servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"assignment_helper.py\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions and Regularization\n",
    "\n",
    "Let's generate an easily, linearly separable dataset and shuffle it into a training set that we are going to optimize over (2/3 of the data), and a test set where we estimate our generalization performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "c1 = np.random.rand(50, 2)/5\n",
    "c2 = (-0.6, 0.5) + np.random.rand(50, 2)/5\n",
    "data = np.concatenate((c1, c2))\n",
    "labels = np.array([0] * 50 + [1] *50)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.subplot(111, xticks=[], yticks=[])\n",
    "plt.scatter(data[:50, 0], data[:50, 1], color='navy')\n",
    "plt.scatter(data[50:, 0], data[50:, 1], color='c')\n",
    "idx = np.arange(len(labels))\n",
    "np.random.shuffle(idx)\n",
    "# train on a random 2/3 and test on the remaining 1/3\n",
    "idx_train = idx[:2*len(idx)//3]\n",
    "idx_test = idx[2*len(idx)//3:]\n",
    "X_train = data[idx_train]\n",
    "X_test = data[idx_test]\n",
    "y_train = labels[idx_train]\n",
    "y_test = labels[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (1 point). A multilayer perceptron is a simple neural network that is composed of perceptrons arranged in layers, mapping from some high-dimensional space to a number of classes. In scikit-learn, it minimizes the cross-entropy $L(\\theta, S) = -\\frac {1}{N}\\sum _{i=1}^N y_i \\log h(\\theta;x_i) + (1-y_i) \\log(1-h(\\theta;x_i))$, where our training set is $S=\\{(x_i, y_i)\\}_{i=1}^N$. Train one such network with default parameters. The model is called `MLPClassifier` in scikit-learn. Place the trained model in an object called `model_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "metric = sklearn.metrics.accuracy_score\n",
    "### BEGIN SOLUTION\n",
    "model_1 = MLPClassifier()\n",
    "model_1.fit(X_train, y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(model_1, sklearn.neural_network.MLPClassifier)\n",
    "assert np.isclose(metric(y_train, model_1.predict(X_train)), 1.0)\n",
    "assert np.isclose(metric(y_test, model_1.predict(X_test)), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (2 points). The model can be regularized by an $l_2$ penalty term, which means that we can penalize it for having large weights in the connections between the perceptrons. For the model you trained, the sum of the square norms is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.linalg.norm(coefs) for coefs in model_1.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strength of the normalization depends on a hyperparameter `alpha` that you can supply when you instantiate the class. Train a heavily regularized version that will have a lower $l_2$ norm for the weights that maintains the training and test accuracy. Place the trained model in an object called `model_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = MLPClassifier(alpha=10)\n",
    "model_2.fit(X_train, y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(model_2, sklearn.neural_network.MLPClassifier)\n",
    "assert np.isclose(metric(y_train, model_2.predict(X_train)), 1.0)\n",
    "assert np.isclose(metric(y_test, model_2.predict(X_test)), 1.0)\n",
    "assert abs(sum(np.linalg.norm(coefs) for coefs in model_1.coefs_)-\n",
    "           sum(np.linalg.norm(coefs) for coefs in model_2.coefs_)) > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, a sparser model (in this case, one with lower $l_2$ norm) provides better guarantees for generalization beyond the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods\n",
    "\n",
    "Ensembles are all about combining diverse models into a single strong classifier. There are countless ways to construct ensembles. One way to ensure diversity is to train the same family of models, but on different subsets of the training data. This is known as [bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating) and it is a way of avoiding overfitting. You can combine bagging with other forms of ensembles to construct robust models.\n",
    "\n",
    "**Exercise 3** (1 point). Random forests do bagging: the algorithm trains many simple decision trees on various subsets of the training data, then averages their output to make predictions. Train a random forest on the above data to maximum accuracy with 20 trees in the ensemble. Place the trained model in an object called `model_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.276015Z",
     "start_time": "2019-01-30T23:03:31.837718Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "### BEGIN SOLUTION\n",
    "model_3 = RandomForestClassifier(n_estimators=20)\n",
    "model_3.fit(X_train, y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.352090Z",
     "start_time": "2019-01-30T23:03:32.277645Z"
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(model_3, sklearn.ensemble.RandomForestClassifier)\n",
    "assert model_3.n_estimators == 20\n",
    "assert np.isclose(metric(y_train, model_3.predict(X_train)), 1.0)\n",
    "assert np.isclose(metric(y_test, model_3.predict(X_test)), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBoost\n",
    "\n",
    "QBoost uses $l_0$ regularization to penalize the number of models in an ensemble and solves this as a discrete optimization problem. We will use the Swiss roll dataset in this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.405417Z",
     "start_time": "2019-01-30T23:03:32.403072Z"
    }
   },
   "outputs": [],
   "source": [
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import sklearn.datasets\n",
    "np.random.seed(0)\n",
    "data, t = sklearn.datasets.make_swiss_roll(n_samples=500)\n",
    "labels = np.array(t<t.mean())\n",
    "idx = np.arange(len(labels))\n",
    "np.random.shuffle(idx)\n",
    "# train on a random 2/3 and test on the remaining 1/3\n",
    "idx_train = idx[:2*len(idx)//3]\n",
    "idx_test = idx[2*len(idx)//3:]\n",
    "X_train = data[idx_train]\n",
    "X_test = data[idx_test]\n",
    "\n",
    "y_train = 2 * labels[idx_train] - 1  # binary -> spin\n",
    "y_test = 2 * labels[idx_test] - 1\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "normalizer = sklearn.preprocessing.Normalizer()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_test = normalizer.fit_transform(X_test)\n",
    "fig = plt.figure()\n",
    "ax = p3.Axes3D(fig)\n",
    "ax.view_init(7, -80)\n",
    "for l in np.unique(labels):\n",
    "    ax.scatter(data[labels == l, 0], data[labels == l, 1], data[labels == l, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (1 point). Train a random forest of twenty trees on this dataset until you get accuracy 1 on the training set. You can ignore the accuracy on the test set. Call this `model_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.412993Z",
     "start_time": "2019-01-30T23:03:32.407859Z"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_4 = RandomForestClassifier(n_estimators=20)\n",
    "model_4.fit(X_train, y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(model_4, sklearn.ensemble.RandomForestClassifier)\n",
    "assert model_4.n_estimators == 20\n",
    "assert np.isclose(metric(y_train, model_4.predict(X_train)), 1.0, rtol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the gap between training and test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric(y_train, model_4.predict(X_train)) - metric(y_test, model_4.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (2 points). The random forest as you trained it gives you twenty weak estimators. Create a function that takes a numpy array of predictions over all weak estimators, the true labels, and a $\\lambda$ parameter for regularization, and returns a quadratic binary optimization of the QBoost objective function for dimod. Your return value is a weight matrix as a dictionary. You can assume that the prediction array's shape is the number of models times the number of training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.420084Z",
     "start_time": "2019-01-30T23:03:32.414819Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_qubo(predictions, y, λ):\n",
    "    ### BEGIN SOLUTION\n",
    "    n_models, n_sample = predictions.shape\n",
    "    w = predictions @ predictions.T/(n_models ** 2)\n",
    "    wii = n_sample / (n_models ** 2) + λ - 2 * predictions @ y/(n_models)\n",
    "    w[np.diag_indices_from(w)] = wii\n",
    "    W = {}\n",
    "    for i in range(n_models):\n",
    "        for j in range(i, n_models):\n",
    "            W[(i, j)] = w[i, j]\n",
    "    return W\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([[-1, 1], [-1, 1]], dtype=np.float64)\n",
    "y = [-1, 1]\n",
    "assert get_qubo(predictions, y, 1) == {(0, 0): -0.5, (0, 1): 0.5, (1, 1): -0.5}\n",
    "assert get_qubo(predictions, y, 10) == {(0, 0): 8.5, (0, 1): 0.5, (1, 1): 8.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the random forest model always predicts 0 or 1 for the individiual weak estimators, so we shift its prediction output to match our spin model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 2*np.array([h.predict(X_train) for h in model_4.estimators_], dtype=np.float64)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (3 points). Using simulated annealing, find a value for the $\\lambda$ parameter that reduces the number of trees used while maintaining the accuracy on the training set. The return value of the sampler should be in an object called `response`. You can use the following function to calculate the prediction of your ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, weights, X):\n",
    "    n_data = len(X)\n",
    "    T = 0\n",
    "    y = np.zeros(n_data)\n",
    "    for i, h in enumerate(models):\n",
    "        y0 = weights[i] * (2*h.predict(X)-1)  # prediction of weak classifier\n",
    "        y += y0\n",
    "        T += np.sum(y0)\n",
    "    y = np.sign(y - T / (n_data*len(models)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "W = get_qubo(predictions, y_train, 15)\n",
    "sampler = dimod.SimulatedAnnealingSampler()\n",
    "response = sampler.sample_qubo(W, num_reads=10)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(response.first.sample.values())\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, predict(model_4.estimators_, weights, X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, predict(model_4.estimators_, weights, X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T23:03:32.559519Z",
     "start_time": "2019-01-30T23:03:32.554979Z"
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(response, dimod.sampleset.SampleSet)\n",
    "weights = list(response.first.sample.values())\n",
    "assert sum(weights) < 20\n",
    "assert np.isclose(metric(y_train, predict(model_4.estimators_, weights, X_train)), 1.0, rtol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, you can do the above optimization on a quantum computer and ideally on larger ensembles. This would eventually lead to a smaller gap between the training and test error, that is, it would lower the variance, although it might sacrifice some of the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
